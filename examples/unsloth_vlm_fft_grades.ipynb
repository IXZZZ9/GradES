{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsloth VLM Full Fine-tuning with GradES\n",
    "\n",
    "This notebook demonstrates how to perform Full Fine-Tuning (FFT) on a Vision-Language Model (VLM) using Unsloth and GradES for gradient-based early stopping. It is based on the dataset and preprocessing from the Unsloth Qwen2.5 VL notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grades\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps trl peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from unsloth import FastVisionModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "\n",
    "from grades import VLMGradEarlyStoppingCallback, VLMGradEarlyStoppingConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model for Full Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\",\n",
    "    load_in_4bit=True,\n",
    "    full_finetuning=True,  # Enable FFT\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"unsloth/LaTeX_OCR\", split=\"train\")\n",
    "\n",
    "instruction = \"Write the LaTeX representation for this image.\"\n",
    "\n",
    "def convert_to_conversation(sample):\n",
    "    conversation = [\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": instruction},\n",
    "            {\"type\": \"image\", \"image\": sample[\"image\"]}\n",
    "        ]},\n",
    "        {\"role\": \"assistant\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": sample[\"text\"]}\n",
    "        ]},\n",
    "    ]\n",
    "    return {\"messages\": conversation}\n",
    "\n",
    "converted_dataset = [convert_to_conversation(sample) for sample in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integrate GradES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlm_config = VLMGradEarlyStoppingConfig(\n",
    "    vision_tau=0.13,\n",
    "    language_tau=0.09,\n",
    "    alpha=0.1,\n",
    "    enable_wandb_logging=False,\n",
    ")\n",
    "vlm_callback = VLMGradEarlyStoppingCallback(vlm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set up Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=converted_dataset,\n",
    "    data_collator=UnslothVisionDataCollator(model, tokenizer),\n",
    "    callbacks=[vlm_callback],\n",
    "    args=SFTConfig(\n",
    "        output_dir=\"unsloth_vlm_fft_grades\",\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        max_steps=60,\n",
    "        learning_rate=2e-5,\n",
    "        logging_steps=5,\n",
    "        report_to=\"none\",\n",
    "        save_strategy=\"no\",\n",
    "        bf16=True,\n",
    "        # Unsloth specific arguments\n",
    "        remove_unused_columns=False,\n",
    "        dataset_text_field=\"\",\n",
    "        dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
